{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing import image\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5002 validated image filenames belonging to 5 classes.\n",
      "Found 1250 validated image filenames belonging to 5 classes.\n",
      "Found 2680 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen_train = image.ImageDataGenerator(rescale=1./255, \n",
    "                                         rotation_range=10, \n",
    "                                         width_shift_range = 0.2, \n",
    "                                         height_shift_range = 0.2, \n",
    "                                         shear_range = 0.2, zoom_range = 0.2, \n",
    "                                         fill_mode = \"nearest\", validation_split=0.20)\n",
    "\n",
    "datagen_test = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "traindf = pd.read_csv('train.csv')\n",
    "testdf = pd.read_csv('test.csv')\n",
    "traindf['category'] = traindf['category'].astype('str')\n",
    "\n",
    "training = datagen_train.flow_from_dataframe(dataframe=traindf,\n",
    "                                             directory=\"./train/\",\n",
    "                                             x_col=\"image\",\n",
    "                                             y_col='category',\n",
    "                                             target_size = (120,120),\n",
    "                                             class_mode = \"categorical\",\n",
    "                                             subset='training',\n",
    "                                             seed=42,shuffle=True)\n",
    "\n",
    "validation = datagen_train.flow_from_dataframe(dataframe=traindf,directory=\"./train/\",\n",
    "                                               x_col=\"image\",y_col='category',\n",
    "                                               target_size = (120,120), class_mode = \"categorical\", subset='validation',\n",
    "                                               seed=42, shuffle=True)\n",
    "\n",
    "testing = datagen_test.flow_from_dataframe(dataframe=testdf, directory=\"./test/\", x_col=\"image\", y_col=None,\n",
    "                                           target_size = (120,120),\n",
    "                                           batch_size = 28,\n",
    "                                           class_mode = None, seed=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def conv2D_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3,3), padding = 'same',\n",
    "                input_shape=(120,120,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) #40x40\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) #20x20\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) #10x10\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (10, 10), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) #5x5\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (10, 10), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) #5x5\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv2D(32, (10, 10), padding='same', activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Conv2D(32, (10, 10), padding='same', activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, (10, 10), padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    # sgd = SGD(lr=0.03, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    STEP_SIZE_TRAIN = training.n // training.batch_size\n",
    "    STEP_SIZE_VALID = validation.n // validation.batch_size\n",
    "\n",
    "    \n",
    "    model.fit_generator(generator=training,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=10,\n",
    "    validation_data=validation,\n",
    "    validation_steps=STEP_SIZE_VALID)\n",
    "    \n",
    "    evaluator = model.evaluate_generator(generator=validation, steps=STEP_SIZE_VALID)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/156 [..............................] - ETA: 5:18:35 - loss: 1.6094 - accuracy: 0.1562"
     ]
    }
   ],
   "source": [
    "model = conv2D_model()\n",
    "\n",
    "print('Saving the model...')\n",
    "\n",
    "model.save('best_model.h5')\n",
    "\n",
    "print('Model Succesfully Trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.reset()\n",
    "\n",
    "# model = load_model('best_model.h5')\n",
    "\n",
    "STEP_SIZE_TEST = testing.n // testing.batch_size\n",
    "predictions = model.predict_generator(testing, steps=STEP_SIZE_TEST, verbose=1)\n",
    "\n",
    "predicted_class_indices = np.argmax(predictions, axis = 1)\n",
    "\n",
    "labels = training.class_indices\n",
    "labels = {value:key for key, value in labels.items()}\n",
    "predictions = [labels[value] for value in predicted_class_indices]\n",
    "print(len(predictions))\n",
    "print(predictions)\n",
    "\n",
    "filenames = [filename for filename in testing.filenames]\n",
    "print(len(filenames))\n",
    "# results = pd.DataFrame({\"Filename\":filenames, \"Predictions\":predictions}, index = None)\n",
    "# results.to_csv(\"Results.csv\", index=False)\n",
    "# print('Results Saved !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
